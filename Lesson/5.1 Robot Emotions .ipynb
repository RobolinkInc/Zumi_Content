{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<img src=\"../Data/images/ZumiHeader.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Robot Emotions\n",
    "\n",
    "<font size =3> Zumi has a personality! In this lesson, you will learn how Zumi detects human emotions as well as how to program Zumiâ€™s personality. You will also learn about sound, how itâ€™s measured, and how it corresponds with emotion.  Finally, you will train your Zumi to recognize and react to her favorite color. </font> \n",
    "\n",
    "\n",
    "\n",
    "## How do we detect emotion?\n",
    "<font size =3> Take a look at the images below and see if you can identify each of the emotions. \n",
    "\n",
    "<img src=\"../Data/images/emotions.png\" width=700> <br>\n",
    "\n",
    "How did you determine which emotion was which? There are many features that can be indicators, like the eyes, mouth, eyebrows, and maybe gestures. How do we translate human emotions to a robot?\n",
    "\n",
    "If you have seen the movie *Cars*, you may know that each of the cars has a personality. How was each car able to express emotions? Was it through movements? Sounds? Eyes? </font> \n",
    "\n",
    "\n",
    "### Import libraries\n",
    "<font size =3> To use personality functions, we need to import the Zumi, screen, and personality libraries. </font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Zumi \n",
      "Pi Zero I2C is available\n",
      "Verified Pi Zero is the same\n",
      "Gyroscope previously calibrated\n",
      "Zumi board detected\n",
      "Compass detected\n",
      "OLED Screen detected\n",
      "Gyroscope & Accelerometer detected\n"
     ]
    }
   ],
   "source": [
    "from zumi.zumi import Zumi\n",
    "from zumi.util.camera import Camera\n",
    "from zumi.util.screen import Screen\n",
    "from zumi.personality import Personality\n",
    "from zumi.util.color_classifier import ColorClassifier\n",
    "import time\n",
    "\n",
    "\n",
    "zumi = Zumi()\n",
    "screen = Screen()\n",
    "personality = Personality(zumi, screen)\n",
    "camera = Camera()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "###  Calling personality functions\n",
    "<font size =3> Here are some functions you can call:\n",
    "\n",
    "* happy()\n",
    "     \n",
    "* celebrate()\n",
    "       \n",
    "* angry()\n",
    "       \n",
    "* look_around()\n",
    "\n",
    "* look_around_open()\n",
    "       \n",
    "* disoriented_left()\n",
    "       \n",
    "* disoriented_right()\n",
    "\n",
    "* awake()\n",
    "\n",
    "For example, \n",
    "<font face=\"Courier\">personality.happy()</font> will make Zumi wiggle and make a sound!\n",
    "            \n",
    "In the cell below, try testing out some of the personality functions to see what they do. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Test Personality code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Sounds\n",
    "\n",
    "<font size =3>Zumi can play sounds to match her emotions! Sound can be measured in frequency and amplitude. \n",
    "\n",
    "*   Frequency is the number of pulses or vibrations per second, and is measured in hertz. The higher the frequency, the higher the pitch of the sound is. \n",
    "*   Amplitude is how loud or strong the sound is and is measured in decibels. The higher the amplitude, the louder the sound is. \n",
    "\n",
    "Video: [Sound: Wavelength, Frequency, and Amplitude](https://www.youtube.com/watch?v=TsQL-sXZOLc)\n",
    "\n",
    "What does each emotion sounds like? Is happy a low or high frequency? Is angry a low or high amplitude? How does this apply to Zumi?\n",
    "\n",
    "You can use <font face=\"Courier\">play_note()</font> to play various notes. The first parameter is the note you want to play (anywhere from C2 to B6). The second parameter is optional and denotes the amount of time you want the note to play in milliseconds. The default value is set to 500ms, but you can change that by adding a second parameter like this: <br><br>\n",
    "<font face=\"Courier\">play_note(Note.GS3, 400)</font>. <br><br>\n",
    "This plays the note G Sharp below middle C for 400 milliseconds. Try the code below to hear a scale and then compose your own music!</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from zumi.protocol import Note \n",
    "zumi.play_note(Note.C4)\n",
    "zumi.play_note(Note.D4)\n",
    "zumi.play_note(Note.E4)\n",
    "zumi.play_note(Note.F4)\n",
    "zumi.play_note(Note.G4)\n",
    "zumi.play_note(Note.A4)\n",
    "zumi.play_note(Note.B4)\n",
    "zumi.play_note(Note.C5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<font size =3> Code your own sounds for happy, sad, angry, or excited. Try out different melodies until you find your favorites. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Make your melodies here ðŸŽµ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Screen\n",
    "\n",
    "<font size =3> Zumi personality also uses the **OLED** (organic LED) screen to display emotions.\n",
    "There are many different \"eyes\" Zumi has:\n",
    "\n",
    "* <font face=\"Courier\"> close_eyes()</font>\n",
    "* <font face=\"Courier\"> sleepy_eyes()</font>\n",
    "* <font face=\"Courier\"> sleepy_left()</font>\n",
    "* <font face=\"Courier\"> sleepy_right()</font>\n",
    "* <font face=\"Courier\"> blink()</font>\n",
    "* <font face=\"Courier\"> look_around_open()</font>\n",
    "* <font face=\"Courier\"> sleeping()</font>\n",
    "* <font face=\"Courier\"> look_around()</font>     \n",
    "* <font face=\"Courier\"> glimmer()</font>\n",
    "* <font face=\"Courier\"> sad()</font>\n",
    "* <font face=\"Courier\"> happy()</font>\n",
    "* <font face=\"Courier\"> hello()</font>\n",
    "* <font face=\"Courier\"> angry()</font>\n",
    "\n",
    "To use the screen, call the screen class with a function of your choice. Try this: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "screen.sad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Draw Text\n",
    "\n",
    "<font size =3> Aside from drawing Zumi eyes, you can also have Zumi write messages on the screen! Use the <font face=\"Courier\">draw_text()</font> function to write a message like this: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "screen.draw_text(\"hello!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =3> If you want to automatically center the text on the screen, call this function instead: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen.draw_text_center(\"hello!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<font size =3> If you want to write text with numbers, you need to make sure everything is of the <font face=\"Courier\">String</font> data type. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "number = 10\n",
    "screen.draw_text(\"ten \" + str(number)) # the str() functions turns the number into a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<font size =3> You can even make Zumi display the time for you! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,50):\n",
    "    screen.draw_text_center(time.ctime())\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eyes on Me\n",
    "<font size = 3> In this activity, Zumi will keep her eyes on you! You will write code so that Zumi eyes follow your face when it's the middle, left, or right side of her line of sight. If Zumi can't see you, Zumi will be sad!\n",
    "This activity uses code from Lesson 4.2 Face Detection. Take a look at that lesson if you haven't yet! </font>\n",
    "    \n",
    "### Dividing the frame into left, right, and middle\n",
    "<font size=3> The first step is to figure out how many pixels wide Zumi's camera images are. To do this, we can access the camera object's properties like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "print(camera.image_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3> By default, the pixel width will always be 160. Although you can change this, we are going to use this valaue in our example. Now, divide this image frame into areas that you will consider the left side of the frame, right side of the frame, and the middle. You can divide it equally or not. It's up to you! Just remember that you only have 160 pixels to divide into three parts and you can't have half of a pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You Smile, I Smile\n",
    "\n",
    "<font size=3> Now that you have learned to use sounds and screen to give Zumi a personality, have her react to a smile! In a previous lesson, you probably learned about using <font face=\"Courier\">vision.find_face()</font> to search for faces. What do you think the features are for a smile? Are the darker pixels of our mouths angled up or down? In this lesson, you will call a function to check if the face Zumi is detecting is smiling. If she sees a smile, she will be happy. If not, give Zumi some sad eyes.</font>\n",
    "    \n",
    "### vision.find_smile()\n",
    "<font size=3> The function you will call for this activity is <font face=\"Courier\">vision.find_smile()</font>. This function will return the pixel coordinates if Zumi finds a smile, or <font face=\"Courier\">(-1,-1,-1,-1)</font> if she doesn't. For example, if you take a picture and save it in an image, you can check if Zumi found a smile or not: <br> <br>\n",
    "    \n",
    "<font face=\"Courier\">\n",
    "    \n",
    "(x,y,w,h) = vision.find_smile(image)<br>\n",
    "if (x,y,w,h) == (-1,-1,-1,-1): <br>\n",
    "<span style=\"margin-left: 40px;\"># Zumi did not find a smile :(</span> <br>\n",
    "else: <br>\n",
    "<span style=\"margin-left: 40px;\"># Zumi sees a smile! :)</span> <br>\n",
    "    </font> </font>\n",
    "    \n",
    "### Code It!\n",
    "<font size=3> Now write some code that will take a picture with Zumi's camera and look for a smile. Give Zumi some personality and match her emotions with yours! Fill in the code template below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "try:\n",
    "    for i in range(1000):\n",
    "        # Finish the code!\n",
    "\n",
    "        \n",
    "finally:\n",
    "    camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<hr>\n",
    "\n",
    "# Extension Activities <br> \n",
    "\n",
    "<img src=\"../Data/images/physics_extension.jpg\" width=70 align=\"left\">\n",
    "\n",
    "###  Frequency <br> \n",
    "<font size =3>Use tuners to identify the frequency, wavelength, and amplitude of different Zumi sounds. Which emotion has the highest or lowest frequency, wavelength, and amplitude? </font><br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
