{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<img src=\"../Data/images/ZumiHeader.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# How does Zumi see?\n",
    "\n",
    "<font size =3> Self-driving cars need a lot more than just obstacle detection sensors. Human drivers have eyes and ears that help us see potential dangers up ahead that maybe a proximity detector can't detect. We can also tell the different between pedestrians, cyclists, and other cars. What else do self-driving cars need to navigate our world?\n",
    "\n",
    "Watch [this](https://www.youtube.com/watch?v=wuhbqcMzOaw) video to see it in action.\n",
    "\n",
    "In this lesson you are going to learn how to access the camera, take pictures, and show video. </font>\n",
    "\n",
    "## Take a Selfie\n",
    "\n",
    "<font size =3> First up: use Zumi's camera to take a picture and display it on the screen! </font>\n",
    "\n",
    "<img src=\"../Data/images/zumi_camera.jpg\" width=500>\n",
    "\n",
    "### Import libraries\n",
    "<font size =3> Import the necessary libraries and create camera objects. </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from zumi.util.camera import Camera\n",
    "from zumi.util.screen import Screen\n",
    "import cv2\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "screen = Screen()\n",
    "camera = Camera()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<font size =3> Just like taking an actual picture, this code has a countdown so you can be prepared.\n",
    "\n",
    "In the code below, the camera is turned on and then the countdown begins. There is a one second delay with <font face=\"Courier\">time.sleep(1)</font> so that there is a one second pause between each number. The rest of the code is commented so that you can see what each line of code does.\n",
    "\n",
    "Get ready to see yourself on the Zumi screen! For multiple pictures, run this cell multiple times. </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Cheese! ðŸ“¸ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "camera.start_camera() # Turn on the camera\n",
    "\n",
    "print(\"3...\")\n",
    "screen.draw_text(\"    3...\")\n",
    "time.sleep(1)\n",
    "print(\"2...\")\n",
    "screen.draw_text(\"    2...\")\n",
    "time.sleep(1)\n",
    "print(\"1...\")\n",
    "\n",
    "screen.draw_text(\"    1...\")\n",
    "time.sleep(1)\n",
    "screen.draw_text(\"    Cheese!\")\n",
    "\n",
    "\n",
    "image = camera.capture() # Take a picture\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Convert it to gray\n",
    "\n",
    "small = cv2.resize(gray, (128,64)) # Resize it to fit the screen\n",
    "    \n",
    "screen.draw_image(Image.fromarray(small).convert('1')) # show the picture! \n",
    "\n",
    "camera.close() # Make sure to close the camera stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Resolution\n",
    "<font size =3> You probably have noticed that the picture is very pixelated and hard to see. That is because the OLED screen is only 128 pixels wide and 64 pixels tall! How many pixels total does the OLED have? </font>\n",
    "\n",
    "### Displaying images  in Jupyter\n",
    "\n",
    "<font size =3> Instead of showing your picture on the Zumi screen, display it right here in the Jupyter Notebook. As a bonus, it will appear in color! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "print(\"3...\")\n",
    "screen.draw_text(\"3...\")\n",
    "time.sleep(1)\n",
    "print(\"2...\")\n",
    "screen.draw_text(\"2...\")\n",
    "time.sleep(1)\n",
    "print(\"1...\")\n",
    "screen.draw_text(\"1...\")\n",
    "time.sleep(1)\n",
    "screen.draw_text(\"Cheese!\")\n",
    "\n",
    "frame = camera.capture()\n",
    "IPython.display.display(Image.fromarray(frame))\n",
    "IPython.display.clear_output(wait=True) \n",
    "time.sleep(5)\n",
    "        \n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Video\n",
    "\n",
    "<font size =3> A video is just a series of pictures one after the other. In order to display a video in Jupyter, you take pictures inside of a <font face=\"Courier\">while True</font> loop. Remember from the remote control lesson that any code inside of a <font face=\"Courier\">while True </font> loop will run forever! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from zumi.util.camera import Camera\n",
    "import cv2\n",
    "import IPython.display\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "camera = Camera()\n",
    "camera.start_camera()\n",
    "\n",
    "try: \n",
    "    while True:\n",
    "        frame = camera.capture()\n",
    "        IPython.display.display(PIL.Image.fromarray(frame))\n",
    "        IPython.display.clear_output(wait=True) \n",
    "\n",
    "finally:\n",
    "    camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Extension Activities <br> \n",
    "\n",
    "<img src=\"../Data/images/physics_extension.jpg\" width=75 align=\"left\">\n",
    "\n",
    "###  Using sensors to take pictures <br> <br>\n",
    "<font size=3> In the section on gyroscopes, we briefly mentioned the accelerometer. The accelerometer measures any changes in speed in each of the three axes: x, y, and z. You can feel the acceleration if you are speeding up or slowing down in a car or rollercoaster. However, if you are moving at a constant speed (neither slowing down nor speeding up) you experience no acceleration. <br>\n",
    "\n",
    "Zumi can feel these accelerations as well, though they may be small. If you shake or tap Zumi, Zumi is moving. For an object to move, or change its velocity, it needs to be accelerated. You can accelerate Zumi by tapping on the shell. A lighter tap is a small acceleration, and a stronger tap may result in a bigger acceleration. This is because acceleration is directly proportional to the force applied. <br> <br>\n",
    "\n",
    "Since the z-axis is already being pulled downward (because of gravity), you will measure Zumi's motion in the x direction (tilting forward or backward). Getting accelerometer data is similar to getting gyro data. First, call <font face=\"Courier\">zumi.mpu.read_all_MPU_data()</font>, which returns a list of accelerometer and gyro values. Since you are only interested in the x-acceleration value, grab the first value in the list in index 0. <br> <br>\n",
    "\n",
    "<font face=\"Courier\"> mpu_list = zumi.mpu.read_all_MPU_data() <br>\n",
    "x_acc = mpu_list[0]</font> <br>\n",
    "\n",
    "\n",
    "Use a while loop to print the x_acc values on the screen and figure out what value it goes above when you tap Zumi. Is it 0.2? 0.3? 0.4? Once you figure out this value, use it with a conditional to trigger the camera to countdown and take a picture.\n",
    "\n",
    "</font>\n",
    "\n",
    "###  Blind spots <br>\n",
    "<font size=3> Cars have blind spots, and Zumi is no exception! While Zumi is taking a picture or video, get a large sheet of paper and draw her field of vision, which will also help you see what she canâ€™t see. Next, complete <a href=\"https://www.exploratorium.edu/snacks/blind-spot\">this blind spot activity</a>. How does this work? Measure the size of your blind spot and compare to Zumiâ€™s. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
