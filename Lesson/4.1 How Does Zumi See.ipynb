{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<img src=\"../Data/images/ZumiHeader.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# How does Zumi see?\n",
    "\n",
    "<font size =3> Self-driving cars need a lot more than just obstacle detection sensors. Human drivers have eyes and ears that help us see potential dangers up ahead that maybe a proximity detector can't detect. We can also tell the different between pedestrians, cyclists, and other cars. What else do self-driving cars need to navigate our world?\n",
    "\n",
    "Watch [this](https://www.youtube.com/watch?v=wuhbqcMzOaw) video to see it in action.\n",
    "\n",
    "In this lesson you are going to learn how to access the camera, take pictures, and show video. </font>\n",
    "\n",
    "## Take a Selfie\n",
    "\n",
    "<font size =3> First up: use Zumi's camera to take a picture and display it on the screen! </font>\n",
    "\n",
    "<img src=\"../Data/images/zumi_camera.jpg\" width=500>\n",
    "\n",
    "### Import libraries\n",
    "<font size =3>Pay attention to the new libraries: the camera and vision libraries! These libraries contains code to take, modify, and display images. </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from zumi.util.camera import Camera\n",
    "from zumi.zumi import Zumi\n",
    "from zumi.util.screen import Screen\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../Resources/\")\n",
    "import vision # New library!\n",
    "\n",
    "zumi = Zumi()\n",
    "camera = Camera()\n",
    "screen = Screen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<font size =3> Just like taking an actual picture, this code has a countdown so you can be prepared.\n",
    "\n",
    "In the code below, the camera is turned on and then the countdown begins. There is a one second delay with <font face=\"Courier\">time.sleep(1)</font> so that there is a one second pause between each number. The rest of the code is commented so that you can see what each line of code does.\n",
    "\n",
    "Get ready to see yourself on the Zumi screen! For multiple pictures, run this cell multiple times. </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Cheese! ðŸ“¸ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "camera.start_camera() # Turn on the camera\n",
    "\n",
    "print(\"3...\")\n",
    "screen.draw_text_center(\"3...\")\n",
    "time.sleep(1)\n",
    "print(\"2...\")\n",
    "screen.draw_text_center(\"2...\")\n",
    "time.sleep(1)\n",
    "print(\"1...\")\n",
    "screen.draw_text_center(\"1...\")\n",
    "time.sleep(1)\n",
    "screen.draw_text_center(\"Cheese!\")\n",
    "\n",
    "image = camera.capture() # Take a picture\n",
    "camera.close() # Make sure to close the camera stream\n",
    "\n",
    "vision.screen_display_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Displaying Images in Jupyter\n",
    "<font size =3>Instead of showing your picture on the Zumi screen, display it right here in the Jupyter Notebook. As a bonus, it will appear in color! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "\n",
    "print(\"3...\")\n",
    "screen.draw_text_center(\"3...\")\n",
    "time.sleep(1)\n",
    "print(\"2...\")\n",
    "screen.draw_text_center(\"2...\")\n",
    "time.sleep(1)\n",
    "print(\"1...\")\n",
    "screen.draw_text_center(\"1...\")\n",
    "time.sleep(1)\n",
    "screen.draw_text_center(\"Cheese!\")\n",
    "\n",
    "frame = camera.capture()\n",
    "camera.close()\n",
    "\n",
    "vision.show_image(frame)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera functions\n",
    "<font size=3> There are three functions that you need to know to use the camera with Zumi: <br><br>\n",
    "    \n",
    " <img src=\"../Data/images/camera_functions.png\">\n",
    "   \n",
    "Before taking a picture, you will need to turn on the camera with <font face=\"Courier\">start_camera()</font>. You cannot take an image without the camera stream! The red light will indicate the camera is on. Next, use <font face=\"Courier\">capture()</font> to take a picture. Save the picture in a variable to display it later. For example, <br><br>\n",
    "    \n",
    "<font face=\"Courier\">frame = camera.capture()</font>  \n",
    "    \n",
    "Finally, don't forget to turn off the camera! If you don't run <font face=\"Courier\">close()</font> and you try to run <font face=\"Courier\">start_camera()</font> again, you will get an error.</font>\n",
    "    \n",
    "### Vision functions\n",
    "<font size=3> The vision library will have everything you need to do things with your images! An image isn't helpful for Zumi if she can't process the image and analyze it. For a human, the image isn't helpful if we can't see it!\n",
    "To show the image in Jupyter, run <font face=\"Courier\">vision.show_image()</font>. Remember that this functions takes in a parameter to know which image to show. In our example, we saved the image in the variable <font face=\"Courier\">frame</font>. So to show the image we would run <br><br>\n",
    "    \n",
    "<font face=\"Courier\">vision.show_image(frame)</font>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Colorspaces\n",
    "<font size =3> If you have ever played around with Photobooth, you may have seen some interesting color filters that make your pictures change colors! Seeing the world differently actually helps computers process images faster, depending on the task.</font>\n",
    "   \n",
    "### Grayscale\n",
    "<font size=3> Grayscale is what we would normally call \"black and white\". However, this is not really accurate because the image is made up of gray pixels as well. Grayscale pictures are faster to process because there are no other colors. You will be using grayscale images later to scan QR codes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Convert it to gray\n",
    "vision.show_image(gray)\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV \n",
    "<font size=3> HSV stands for **hue**, **saturation**, and **value**. Even though the image might look strange to you, this colorspace is useful for when Zumi needs to detect or track certain colors. It is more useful than the normal colored image that you are used to because each pixel of information can tell the computer about the color's intensity and whether or not there are shadows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # Convert it to HSV, hue saturation and value\n",
    "vision.show_image(hsv)\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted\n",
    "<ont size=3> This one is just for fun! This filter inverts the tones of the color. For example, lighter areas become darker and darker areas become lighter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "invert = cv2.bitwise_not(frame) # invert the colors\n",
    "vision.show_image(invert)\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolution\n",
    " <font size =3> You probably noticed that the pictures you took on the OLED were not very detailed.That is because the OLED screen is only 128 pixels wide and 64 pixels tall! You've heard us mention pixels before, but let's look at an example: <br>\n",
    "    \n",
    "<img src=\"../Data/images/grayscale.png\">\n",
    "    \n",
    "This image is 770 pixels wide and 600 pixels tall. Each pixel is a little square of color. You can't really see them until you zoom in. Look at the eyes more closely: <br> <br>\n",
    "      \n",
    "<img src=\"../Data/images/pixels.png\" width=700>  \n",
    "    \n",
    "Now you can see the individual pixels. There are 770 of them in one row and 600 in each column! If you had even more pixels the picture would be considered a **high resolution** image. In contrast, the resolution of the OLED is low. </font>\n",
    " \n",
    "### Changing resolution\n",
    "<font size=3> Although you cannot change the resolution of the OLED, you can increase the resolution of the images that the camera takes. Run the next cell to take a picture (there is not countdown this time so be ready!). What do you think the resolution is? Guess how many pixels wide and tall the image is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "vision.show_image(frame)\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3> The default resolution for the Zumi camera is 160x120. Try changing these values below and watch your image stretch, shrink, and get bigger!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your values here!\n",
    "width = 80\n",
    "height = 64\n",
    "\n",
    "camera = Camera(width,height) # Let the camera know what changes you are making!\n",
    "\n",
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "vision.show_image(frame)\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =3> There is a size limit! Here we will take a full resolution image. You will notice that Zumi will take more time to process and display the image. Why do you think so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1296 # Largest resolution!\n",
    "height = 976\n",
    "\n",
    "camera = Camera(width,height)\n",
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "IPython.display.display(Image.fromarray(frame))\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Video\n",
    "\n",
    "<font size =3> Although a video looks seamless, a video is actually a series of pictures one after the other. The images are shown so fast that you normally do not notice a difference. However, you may notice the difference here, especially if your images are very large. In order to display a video, take and display pictures inside of a for loop. \n",
    "<font size =3>Fill in the code below to show video. Since you will be using a loop, we are going to introduce something that will help keep your code from crashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "camera = Camera()\n",
    "camera.start_camera()\n",
    "\n",
    "try:\n",
    "    for x in range(30):\n",
    "        # TODO Take a picture\n",
    "        # TODO show the picture\n",
    "        vision.clear_output() # Clear the output for the next image to show\n",
    "finally:\n",
    "    camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3> You will notice that there are two new sections of code: <font face=\"Courier\">try</font> and <font face=\"Courier\">finally</font>. If anything goes wrong or you stop your code while in the <font face=\"Courier\">try</font> section, the program will automatically jump to the <font face=\"Courier\">finally</font> statements. In this case, we put a <font face=\"Courier\">close()</font> for the camera so that you never have to worry about it staying on. </font>\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
