{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<img src=\"../Data/images/ZumiHeader.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# How does Zumi see?\n",
    "\n",
    "<font size =3> Self-driving cars need a lot more than just obstacle detection sensors. Human drivers have eyes and ears that help us see potential dangers up ahead that maybe a proximity detector can't detect. We can also tell the different between pedestrians, cyclists, and other cars. What else do self-driving cars need to navigate our world?</font>\n",
    "\n",
    "\n",
    "## Take a Selfie\n",
    "\n",
    "<font size =3> First up: use Zumi's camera to take a picture and display it on the screen! </font>\n",
    "\n",
    "<img src=\"../Data/images/zumi_camera.jpg\" width=500>\n",
    "\n",
    "### Import libraries\n",
    "<font size =3>Pay attention to the new libraries: the camera and vision libraries! These libraries contains code to take, modify, and display images. </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Zumi \n",
      "Pi Zero I2C is available\n",
      "Verified Pi Zero is the same\n",
      "Gyroscope previously calibrated\n",
      "Zumi board detected\n",
      "Compass detected\n",
      "OLED Screen detected\n",
      "Gyroscope & Accelerometer detected\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/pi/zumi-python-library\")\n",
    "from zumi.util.camera import Camera # New library!\n",
    "from zumi.zumi import Zumi\n",
    "from zumi.util.screen import Screen\n",
    "import cv2\n",
    "import time\n",
    "from zumi.util.vision import Vision # New library!\n",
    "\n",
    "zumi = Zumi()\n",
    "camera = Camera()\n",
    "screen = Screen()\n",
    "vision = Vision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<font size =3> Just like taking an actual picture, this code has a countdown so you can be prepared. Run the code and smile! Get ready to see yourself on the Zumi screen!</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Cheese! ðŸ“¸ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PiCamera\n",
      "3...\n",
      "2...\n",
      "1...\n",
      "Closing PiCamera\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-df2980c36bbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Take a picture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Make sure to close the camera stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen_display_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Display image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/zumi-python-library/zumi/util/camera.py\u001b[0m in \u001b[0;36mscreen_display_image\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0msmall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Resize it to fit the screen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mscreen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScreen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mscreen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# show the picture!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "camera.start_camera() # Turn on the camera\n",
    "\n",
    "print(\"3...\")\n",
    "screen.draw_text_center(\"3...\")\n",
    "time.sleep(1)\n",
    "print(\"2...\")\n",
    "screen.draw_text_center(\"2...\")\n",
    "time.sleep(1)\n",
    "print(\"1...\")\n",
    "screen.draw_text_center(\"1...\")\n",
    "time.sleep(1)\n",
    "screen.draw_text_center(\"Cheese!\")\n",
    "\n",
    "image = camera.capture() # Take a picture\n",
    "camera.close() # Make sure to close the camera stream\n",
    "camera.screen_display_image(image) # Display image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Displaying Images in Jupyter\n",
    "<font size =3>Instead of showing your picture on the Zumi screen, display it right here in the Jupyter Notebook. As a bonus, it will appear in color! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "\n",
    "print(\"3...\")\n",
    "screen.draw_text_center(\"3...\")\n",
    "time.sleep(1)\n",
    "print(\"2...\")\n",
    "screen.draw_text_center(\"2...\")\n",
    "time.sleep(1)\n",
    "print(\"1...\")\n",
    "screen.draw_text_center(\"1...\")\n",
    "time.sleep(1)\n",
    "screen.draw_text_center(\"Cheese!\")\n",
    "\n",
    "frame = camera.capture()\n",
    "camera.close()\n",
    "\n",
    "camera.display_image(frame)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera functions\n",
    "<font size=3> There are three functions that you need to know to use the camera with Zumi: <br><br>\n",
    "    \n",
    " <img src=\"../Data/images/camera_functions.png\">\n",
    "   \n",
    "Before taking a picture, you will need to turn on the camera with <font face=\"Courier\">start_camera()</font>. You cannot take an image without the camera stream! The red light will indicate the camera is on. Next, use <font face=\"Courier\">capture()</font> to take a picture. Save the picture in a variable to display it later. For example, <br><br>\n",
    "    \n",
    "<font face=\"Courier\">frame = camera.capture()</font>  \n",
    "    \n",
    "Finally, don't forget to turn off the camera! If you don't run <font face=\"Courier\">close()</font> and you try to run <font face=\"Courier\">start_camera()</font> again, you will get an error.</font>\n",
    "\n",
    "### Show the image\n",
    "<font size=3> Zumi doesn't need to \"see\" the image like we do to process it because all she sees is numbers! To show what we mean, write code below that takes a picture and saves it in a variable. Then, print the variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here!\n",
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "camera.close()\n",
    "\n",
    "print(frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>But for humans, we need to see the image as pixels of color to understand it. As you saw in the code above,\n",
    "to show the image in Jupyter, run <font face=\"Courier\">camera.show_image()</font>. Remember that this functions takes in a parameter to know which image to show. In our example, we saved the image in the variable <font face=\"Courier\">frame</font>. So to show the image we would run <br><br>\n",
    "<font face=\"Courier\">camera.show_image(frame)</font></font>  \n",
    "    \n",
    "## Changing Colorspaces\n",
    "<font size =3> If you have ever played around with Photobooth, you may have seen some interesting color filters that make your pictures change colors! Seeing the world differently actually helps computers process images faster, depending on the task.</font>\n",
    "\n",
    "<img src=\"../Data/images/color_filters.png\" width=400>\n",
    "   \n",
    "### Grayscale\n",
    "<font size=3> Grayscale is what we would normally call \"black and white\". However, this is not really accurate because the image is made up of gray pixels as well. Grayscale pictures are faster to process because there are no other colors. You will be using grayscale images later to scan QR codes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "gray = vision.convert_to_gray(frame) # Convert it to gray\n",
    "camera.show_image(gray)\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV \n",
    "<font size=3> HSV stands for **hue**, **saturation**, and **value**. Even though the image might look strange to you, this colorspace is useful for when Zumi needs to detect or track certain colors. It is more useful than the normal colored image that you are used to because each pixel of information can tell the computer about the color's intensity and whether or not there are shadows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "hsv = vision.convert_to_hsv(frame) # Convert it to HSV, hue saturation and value\n",
    "camera.show_image(hsv)\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted\n",
    "<ont size=3> This one is just for fun! This filter inverts the tones of the color. For example, lighter areas become darker and darker areas become lighter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "invert = cv2.bitwise_not(frame) # invert the colors\n",
    "camera.show_image(invert)\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolution\n",
    " <font size =3> You probably noticed that the pictures you took on the OLED were not very detailed.That is because the OLED screen is only 128 pixels wide and 64 pixels tall! You've heard us mention pixels before, but let's look at an example. The image on the left is 770 pixels wide and 600 pixels tall. Each pixel is a little square of color. You can't really see them until you zoom in. Look at the eyes more closely on the second image:<br>\n",
    "<table><tr>\n",
    "<td> <img src=\"../Data/images/grayscale.png\" width=400> </td>\n",
    "<td> <img src=\"../Data/images/pixels.png\" width=400>   </td>\n",
    "</tr></table>   \n",
    "    \n",
    " \n",
    "    \n",
    "<br> <br>\n",
    "      \n",
    "\n",
    "    \n",
    "In the second image, you can see the individual pixels. There are 770 of them in one row and 600 in each column! If you had even more pixels the picture would be considered a **high resolution** image. In contrast, the resolution of the OLED is low. </font>\n",
    " \n",
    "### Changing resolution\n",
    "<font size=3> Although you cannot change the resolution of the OLED, you can increase the resolution of the images that the camera takes. Run the next cell to take a picture (there is not countdown this time so be ready!). What do you think the resolution is? Guess how many pixels wide and tall the image is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "camera.show_image(frame)\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Try changing these values below and watch your image stretch, shrink, and get bigger!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 160 # <-- CHANGE ME!\n",
    "height = 120 # <-- CHANGE ME!\n",
    "\n",
    "camera = Camera(width,height) # Let the camera know what changes you are making!\n",
    "\n",
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "camera.show_image(frame)\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =3> There is a size limit! Here we will take a full resolution image. You will notice that Zumi will take more time to process and display the image. Why do you think so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1296 # Largest resolution!\n",
    "height = 976\n",
    "\n",
    "camera = Camera(width,height)\n",
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "camera.show_image()\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Video\n",
    "\n",
    "<font size =3> Although a video looks seamless, a video is actually a series of pictures one after the other. The images are shown so fast that you normally do not notice a difference. However, you may notice the difference here, especially if your images are very large. In order to display a video, take and display pictures inside of a for loop. \n",
    "<font size =3>Fill in the code below to show video. Since you will be using a loop, we are going to introduce something that will help keep your code from crashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "camera = Camera()\n",
    "camera.start_camera()\n",
    "\n",
    "try:\n",
    "    for x in range(30):\n",
    "        # TODO Take a picture\n",
    "        # TODO show the picture\n",
    "        vision.clear_output() # Clear the output for the next image to show\n",
    "finally:\n",
    "    camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3> You will notice that there are two new sections of code: <font face=\"Courier\">try</font> and <font face=\"Courier\">finally</font>. If anything goes wrong or you stop your code while in the <font face=\"Courier\">try</font> section, the program will automatically jump to the <font face=\"Courier\">finally</font> statements. In this case, we put a <font face=\"Courier\">close()</font> for the camera so that you never have to worry about it staying on. </font>\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
